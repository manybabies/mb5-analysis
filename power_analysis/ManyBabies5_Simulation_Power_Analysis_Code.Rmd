---
title: "ManyBabies 5: The Hunter and Ames Model of Infant Looking Preference"
subtitle: "Supplementary Materials: Data Simulation and Power Analysis"
author: "ManyBabies Analysis Team"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
  html_document: default
editor_options:
  chunk_output_type: console
geometry: margin=0.8cm
---

```{r setup, include=FALSE}
pacman::p_load(brms,
               knitr, # rendering of .Rmd file
               lme4, # model specification / estimation
               afex, # anova and deriving p-values from lmer
               broom.mixed, # extracting data from model fits 
               faux, # generate correlated values
               tidyverse, # data wrangling and visualisation
               ggridges, #visualisation
               viridis, # color schemes for visualisation
               kableExtra,
               cowplot,
               performance,
               see
               )
set.seed(1234)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE, fig.width=12, fig.height=11, fig.fullwidth=TRUE)
```

```{r, include = FALSE}
filename_full_int_0.1 = 'sims/run_sims_full_int_0.1.csv'
filename_full_int_0.2 = 'sims/run_sims_full_int_0.2.csv'
filename_full_int_0.3 = 'sims/run_sims_full_int_0.3.csv'
filename_full_int_0.5 = 'sims/run_sims_full_int_0.4.csv'
filename_full_int_0.4 = 'sims/run_sims_full_int_0.5.csv'

filename_full_0.1 = 'sims/run_sims_full_0.1.csv'
filename_full_0.2 = 'sims/run_sims_full_0.2.csv'
filename_full_0.3 = 'sims/run_sims_full_0.3.csv'
filename_full_0.4 = 'sims/run_sims_full_0.4.csv'
filename_full_0.5 = 'sims/run_sims_full_0.5.csv'

filename_20_missing_0.1 = 'sims/run_sims_20_missing_0.1.csv'
filename_20_missing_0.2 = 'sims/run_sims_20_missing_0.2.csv'
filename_20_missing_0.3 = 'sims/run_sims_20_missing_0.3.csv'
filename_20_missing_0.4 = 'sims/run_sims_20_missing_0.4.csv'
filename_20_missing_0.5 = 'sims/run_sims_20_missing_0.5.csv'

filename_50_missing_0.1 = 'sims/run_sims_50_missing_0.1.csv'
filename_50_missing_0.2 = 'sims/run_sims_50_missing_0.2.csv'
filename_50_missing_0.3 = 'sims/run_sims_50_missing_0.3.csv'
filename_50_missing_0.4 = 'sims/run_sims_50_missing_0.4.csv'
filename_50_missing_0.5 = 'sims/run_sims_50_missing_0.5.csv'

filename_heteroskedasticity = 'sims/filename_heteroskedasticity.csv'

filename_full_0.3_missing_age = 'sims/run_sims_0.3_age_missing.csv'
filename_full_0.3_missing_trial = 'sims/run_sims_0.3_trial_missing.csv'
filename_full_0.3_missing_fam = 'sims/run_sims_0.3_fam_missing.csv'

reps <- 500
```

\newpage

# Data Simulation

```{r, message = FALSE}
my_sim_data <- function(
    n_subj      = 1280,   # number of subjects
    n_simple  =  6,   # number of complex stimuli
    n_complex =  6,   # number of complex stimuli
    n_small_fam = 4,   #small familiarization time
    n_medium_fam = 4,  #medium familiarization time
    n_high_fam = 4,    #high familiarization time
    n_lab = 40,
    
    beta_0  =  0, # intercept; i.e., the grand mean
    beta_c  =  0.3, # main effect for complexity
    beta_f = 0.3, # main effect for familiarization time
    beta_a = 0.3, # main effect for age
    
    beta_ca = 0.3,
    beta_af = 0.3,
    beta_cf = 0.3,
    
    beta_cfa = 0.3, #main effect for interaction between complexity and familiarization.
    
    subject_0   = 0.2, # by-subject random intercept sd
    
    subject_c   =  0.2, # by-subject slope complexity sd
    subject_f = 0.2, # by-subject slope familiarization sd
    subject_a = 0.2, # by-subject slope age sd
    
    subject_ca = 0.2,# by-subject slope for interaction between age and complexity sd
    subject_af = 0.2, # by-subject slope for interaction between age and familiarization sd
    subject_cf = 0.2, # by-subject slope complexity*familiarization sd
    
    subject_cfa = 0.2, # by-subject slope for interaction between age, complexity and familiarization sd

    subj_rho     =  .2, # correlations between by-subject random effects
    
    lab_0 = 0.2, # by-lab random intercept sd
    
    lab_c = 0.2, # by-lab slope complexity sd
    lab_f = 0.2, # by-lab slope familiarization sd
    lab_a = 0.2, # by-lab slope age sd
    
    lab_ca = 0.2, # by-lab slope for interaction between age and complexity sd
    lab_af = 0.2, # by-lab slope for interaction between age and familiarization sd
    lab_cf = 0.2, # by-lab random slope complexity*familiarization sd
    
    lab_cfa = 0.2, # by-lab slope for interaction between age, complexity and familiarization sd
    
    lab_rho = 0.2, # correlations between by-lab random effects
    
    item_0 =  0.05, # by-item random intercept sd
    
    item_c = 0.05, # by-item slope complexity sd
    item_f = 0.05, # by-item slope familiarization sd
    item_a = 0.05, # by-item slope age sd
    
    item_ca = 0.05, # by-item slope for interaction between age and complexity sd
    item_af = 0.05, # by-item slope for interaction between age and familiarization sd
    item_cf = 0.05, # by-item random slope complexity*familiarization sd
    
    item_cfa = 0.05, # by-item slope for interaction between age, complexity and familiarization sd
    
    item_rho = 0.2, # correlations between by-item random effects
    
    
    sigma = 0.3 # residual (error) sd
    ) { # residual (standard deviation)
  
  # simulate a sample of items
  items <- data.frame(
    category = rep(c("simple", "complex"), c(n_simple, n_complex)),
    X_c = rep(c(-0.5, 0.5), c(n_simple, n_complex)),
    familiarization = rep(c("short", "medium", "long"), (n_simple + n_complex)/3),
    X_f = rep(c(-0.5, 0, 0.5), (n_simple + n_complex)/3),
    faux::rnorm_multi(
    n = n_simple + n_complex, mu = 0, sd = c(item_0, 
                               item_c, 
                               item_f,
                               item_a,
                               item_ca,
                               item_af,
                               item_cf,
                               item_cfa), r = item_rho,
    varnames = c("I_0", "I_c","I_f","I_a",
                 "I_ca","I_af", "I_cf",
                 "I_cfa"))
    ) %>%
    mutate(item_id = faux::make_id(nrow(.), "I"))
  
  # simulate a sample of subjects
  subjects <- 
    faux::rnorm_multi(
    n = n_subj, mu = 0, sd = c(subject_0, 
                               subject_c, 
                               subject_f,
                               subject_a,
                               subject_ca,
                               subject_af,
                               subject_cf,
                               subject_cfa), r = subj_rho,
    varnames = c("S_0", "S_c","S_f","S_a",
                 "S_ca","S_af", "S_cf",
                 "S_cfa")
  ) %>%
    mutate(subj_id = faux::make_id(nrow(.), "S")) %>%
    mutate(X_a = runif(n_subj, min = -0.5, max = 0.5)) 
  #add subject age measure, sample from distribution from -0.5 to 0.5. #subjects$subj_id <- 1:n_subj
  
  labs <- faux::rnorm_multi(
    n = n_lab, mu = 0, sd = c(lab_0, lab_c, lab_f, lab_a,
                              lab_ca, lab_af, lab_cf,
                              lab_cfa), r = lab_rho, 
    varnames = c("L_0", "L_c","L_f","L_a",
                 "L_ca","L_af", "L_cf",
                 "L_cfa")
  ) %>%
    mutate(lab_id = faux::make_id(nrow(.), "L"))
  
  #create lab and subj nesting structure
  #Number of subjects must be a multiple of number of labs
  lab_multiplier = n_subj/n_lab
  lab_subj_dict <- data.frame(
    subj_id = subjects$subj_id,
    lab_id = rep(labs$lab_id,lab_multiplier)
  )
  
  # cross subject and item IDs 
  temp <- crossing(subjects, items)  %>%
    left_join(lab_subj_dict, by = "subj_id") %>%
    left_join(labs, by = "lab_id") %>%
    group_by(subj_id, item_id) %>% 
    mutate(item_id = sample(item_id)) %>%
    ungroup() %>%
    mutate(trial_num = rep(seq(n_simple + n_complex), n_subj))
  
  temp <- temp %>%
    mutate(
      B_0  = beta_0 + S_0 + L_0 + I_0,
      
      B_c  = beta_c + S_c + L_c + I_c,
      B_f  = beta_f + S_f + L_f + I_f,
      B_a = beta_a + S_a + L_a + I_a,
      
      B_ca = beta_ca + S_ca + L_ca + I_ca,
      B_af = beta_af + S_af + L_af + I_af,
      B_cf = beta_cf + S_cf + L_cf + I_cf,
      
      B_cfa = beta_cfa + S_cfa + L_cfa + I_cfa,
      
      e_si = rnorm(nrow(temp), mean = 0, sd = sigma),
      
      DV = B_0 + 
        (B_a * X_a) + (B_c * X_c) + (B_f * X_f) + 
        (B_cf * X_c * X_f) + (B_af * X_a * X_f) + (B_ca * X_c * X_a) + 
        (B_cfa * X_c * X_f * X_a) + e_si
    )
}

dat_sim <- my_sim_data()
```

# Visualisation of Simulated Data

## Familiarization:

```{r}
dat_sim_plot_familiarization <- dat_sim %>%
  group_by(X_f) %>%
  dplyr::summarise(med_DV = median(DV))

plot_familiarization <- dat_sim %>%
  mutate(X_f = as.factor(X_f)) %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_f), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_violin(aes(y = DV, x = X_f, fill = familiarization), alpha = 0.2) +
  geom_line(aes(y = med_DV, x = as.factor(X_f), group = 1), data = dat_sim_plot_familiarization) +
  geom_point(aes(y = med_DV, x = as.factor(X_f)), alpha = 0.8, size = 2, data = dat_sim_plot_familiarization) +
  scale_fill_manual(values=viridis(n = 3)) +
  ggtitle('Familiarization') +
  xlab('Familiarization') +
  theme_bw()

plot_familiarization <- plot_familiarization + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_familiarization
```

## Complexity:

```{r}
dat_sim_plot_complexity <- dat_sim %>%
  group_by(X_c) %>%
  dplyr::summarise(med_DV = median(DV))

plot_complexity <- dat_sim %>%
  mutate(X_c = as.factor(X_c)) %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_c), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_violin(aes(y = DV, x = X_c, fill = category), alpha = 0.2) +
  geom_line(aes(y = med_DV, x = as.factor(X_c), group = 1), data = dat_sim_plot_complexity) +
  geom_point(aes(y = med_DV, x = as.factor(X_c)), alpha = 0.8, size = 2, data = dat_sim_plot_complexity) +
  scale_fill_manual(values=viridis(n = 2)) +
  ggtitle('Stimulus Complexity') +
  xlab('Stimulus Complexity') +
  theme_bw()

plot_complexity <- plot_complexity + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_complexity
```

## Age:

```{r}
plot_age <- dat_sim %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_a), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, aes(y = DV, x = X_a)) +
  ggtitle('Age') + 
  xlab('Age') +
  theme_bw()
  
plot_age <- plot_age + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_age
```


## Age*Familiarization:

```{r}
plot_age_familiarization <- dat_sim %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_a), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_smooth(method = "lm", formula = y ~ x, se = TRUE, aes(y = DV, x = X_a)) +
  facet_wrap(~X_f) +
  ggtitle('Age x Familiarization Interaction') +
  xlab('Age') +
  theme_bw()
plot_age_familiarization <- plot_age_familiarization + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_age_familiarization
```


## Age*Complexity:

```{r}
plot_age_complexity <- dat_sim %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_a), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_smooth(method = "lm", formula = y ~ x, se = TRUE, aes(y = DV, x = X_a)) +
  facet_wrap(~X_c) +
  ggtitle('Age x Complexity Interaction') +
  xlab('Age') +
  theme_bw()

plot_age_complexity <- plot_age_complexity + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_age_complexity
```


## Familiarization*Complexity:

```{r}
dat_f_c_interaction <- dat_sim %>%
  mutate(X_c = as.factor(X_c)) %>%
  mutate(X_f = as.factor(X_f)) %>%
  group_by(X_f, X_c) %>%
  dplyr::summarise(med_DV = median(DV))

plot_familiarization_complexity <- dat_sim %>%
  mutate(X_c = as.factor(X_c)) %>%
  mutate(X_f = as.factor(X_f)) %>%
  ggplot() +
  geom_point(aes(y = DV, x = X_f), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_point(aes(y = med_DV, x = as.factor(X_f)), alpha = 0.8, size = 2, data = dat_f_c_interaction) +
  geom_line(aes(y = med_DV, x = as.factor(X_f), group = 1), data = dat_f_c_interaction) +
  geom_violin(aes(y = DV, x = X_f, fill = familiarization), alpha = 0.2) +
  scale_fill_manual(values=viridis(n = 3)) +
  facet_wrap(~X_c) +
  ggtitle('Familiarization x Complexity Interaction') +
  xlab('Familiarization') +
  theme_bw()
plot_familiarization_complexity <- plot_familiarization_complexity + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_familiarization_complexity
```

## Variability by Lab
```{r, fig.height=14, warning=FALSE, echo=FALSE, message = FALSE}
plot_labs <- dat_sim %>%
  mutate(lab_id = as.factor(lab_id)) %>%
  ggplot() +
  geom_density_ridges(aes(y = reorder(lab_id, DV), x = DV, color = "black", fill = lab_id), show.legend = FALSE, quantile_lines = TRUE, quantiles = c(0.025, 0.5, 0.975), alpha = 0.4, scale = 1.1) +
  ggtitle('Variability by Lab') +
  geom_vline(xintercept = 0, color = "black", size = 0.3, linetype = "dotted") +
  xlab('DV') +
  ylab('Lab') +
  xlim(c(-2, 2)) +
  scale_color_manual(values=c(viridis(n = 40))) +
  scale_fill_manual(values=c(viridis(n = 40))) +
  theme_bw()

plot_labs <- plot_labs + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_labs
```

## Variability by Item
```{r, fig.height=14, warning=FALSE, echo=FALSE, message = FALSE}
plot_item <- dat_sim %>%
  mutate(item_id = as.factor(item_id)) %>%
  ggplot() +
  geom_density_ridges(aes(y = reorder(item_id, DV), x = DV, color = "black", fill = item_id), show.legend = FALSE, quantile_lines = TRUE, quantiles = c(0.025, 0.5, 0.975), alpha = 0.4, scale = 1.1) +
  ggtitle('Variability by Item') +
  geom_vline(xintercept = 0, color = "black", size = 0.3, linetype = "dotted") +
  xlab('DV') +
  ylab('Item') +
  xlim(c(-2, 2)) +
  scale_color_manual(values=c(viridis(n = 24))) +
  scale_fill_manual(values=c(viridis(n = 24))) +
  theme_bw()

plot_item <- plot_item + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_item
```


# Overview of Power Simulation Results

## Summary Statistics for Power Calculation with Full Data and Varying Intercepts and Varying Slopes:

```{r, message = FALSE, warning = FALSE, echo = FALSE}
setwd("/work")
# calculate mean estimates and power for specified alpha
alpha <- 0.05

sim_stats_full_0.5 <- 
  read_csv(filename_full_0.5, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.5" = mean(p.value < alpha),
    "bias, ef = 0.5" = 0.5 - median_estimate
  )
sim_stats_full_0.5[1,5] <- sim_stats_full_0.5[1,5] - 0.5

sim_stats_full_0.4 <-
  read_csv(filename_full_0.4, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.4" = mean(p.value < alpha),
    "bias, ef = 0.4" = 0.4 - median_estimate
  )

sim_stats_full_0.4[1,5] <- sim_stats_full_0.4[1,5] - 0.4

sim_stats_full_0.3 <-
  read_csv(filename_full_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.3" = mean(p.value < alpha),
    "bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_full_0.3[1,5] <- sim_stats_full_0.3[1,5] - 0.3

sim_stats_full_0.2 <-
  read_csv(filename_full_0.2, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.2" = mean(p.value < alpha),
    "bias, ef = 0.2" = 0.2 - median_estimate
  )

sim_stats_full_0.2[1,5] <- sim_stats_full_0.2[1,5] - 0.2

sim_stats_full_0.1 <-
  read_csv(filename_full_0.1, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.1" = mean(p.value < alpha),
    "bias, ef = 0.1" = 0.1 - median_estimate
  )

sim_stats_full_0.1[1,5] <- sim_stats_full_0.1[1,5] - 0.1

sim_stats_full <- cbind(sim_stats_full_0.3[,1], 
                        sim_stats_full_0.1[,4], 
                        sim_stats_full_0.2[,4], 
                        sim_stats_full_0.3[,4], 
                        sim_stats_full_0.4[,4], 
                        sim_stats_full_0.5[,4])

sim_stats_full %>%
  kbl(caption = "Power for Simulations with Full Data and Varying Intercepts and Varying Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_full_bias_int_slope <- 
  cbind(sim_stats_full_0.3[,1], 
        sim_stats_full_0.1[,5], 
        sim_stats_full_0.2[,5], 
        sim_stats_full_0.3[,5], 
        sim_stats_full_0.4[,5], 
        sim_stats_full_0.5[,5])
```

## Summary Statistics for Power Calculation with Full Data and Varying Intercepts:

```{r, message = FALSE, warning = FALSE, echo = FALSE}
sim_stats_full_0.5 <- 
  read_csv(filename_full_int_0.5, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.5" = mean(p.value < alpha),
    "bias, ef = 0.5" = 0.5 - median_estimate
  )

sim_stats_full_0.5[1,5] <- sim_stats_full_0.5[1,5] - 0.5

sim_stats_full_0.4 <-
  read_csv(filename_full_int_0.4, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.4" = mean(p.value < alpha),
    "bias, ef = 0.4" = 0.4 - median_estimate
  )

sim_stats_full_0.4[1,5] <- sim_stats_full_0.4[1,5] - 0.4

sim_stats_full_0.3 <-
  read_csv(filename_full_int_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.3" = mean(p.value < alpha),
    "bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_full_0.3[1,5] <- sim_stats_full_0.3[1,5] - 0.3

sim_stats_full_0.2 <-
  read_csv(filename_full_int_0.2, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.2" = mean(p.value < alpha),
    "bias, ef = 0.2" = 0.2 - median_estimate
  )
sim_stats_full_0.2[1,5] <- sim_stats_full_0.2[1,5] - 0.2

sim_stats_full_0.1 <-
  read_csv(filename_full_int_0.1, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.1" = mean(p.value < alpha),
    "bias, ef = 0.1" = 0.1 - median_estimate
  )
sim_stats_full_0.1[1,5] <- sim_stats_full_0.1[1,5] - 0.1

sim_stats_full <- cbind(sim_stats_full_0.3[,1], 
                        sim_stats_full_0.1[,4], 
                        sim_stats_full_0.2[,4], 
                        sim_stats_full_0.3[,4], 
                        sim_stats_full_0.4[,4], 
                        sim_stats_full_0.5[,4])

sim_stats_full %>%
  kbl(caption = "Power for Simulations with Full Data and Varying Intercepts", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_full_bias_int <- 
  cbind(sim_stats_full_0.3[,1], 
        sim_stats_full_0.1[,5], 
        sim_stats_full_0.2[,5], 
        sim_stats_full_0.3[,5], 
        sim_stats_full_0.4[,5], 
        sim_stats_full_0.5[,5])
```

## Summary Statistics for Power Calculation with 20 pct. Missing Data and Varying Intercepts:

```{r, message = FALSE, warning = FALSE, echo = FALSE}
sim_stats_20_missing_0.5 <-
  read_csv(filename_20_missing_0.5, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.5" = mean(p.value < alpha),
    "bias, ef = 0.5" = 0.5 - median_estimate
  )

sim_stats_20_missing_0.5[1,5] <- sim_stats_20_missing_0.5[1,5] - 0.5

sim_stats_20_missing_0.4 <-
  read_csv(filename_20_missing_0.4, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.4" = mean(p.value < alpha),
    "bias, ef = 0.4" = 0.4 - median_estimate
  )

sim_stats_20_missing_0.4[1,5] <- sim_stats_20_missing_0.4[1,5] - 0.4

sim_stats_20_missing_0.3 <-
  read_csv(filename_20_missing_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.3" = mean(p.value < alpha),
    "bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_20_missing_0.3[1,5] <- sim_stats_20_missing_0.3[1,5] - 0.3

sim_stats_20_missing_0.2 <-
  read_csv(filename_20_missing_0.2, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.2" = mean(p.value < alpha),
    "bias, ef = 0.2" = 0.2 - median_estimate
  )

sim_stats_20_missing_0.2[1,5] <- sim_stats_20_missing_0.2[1,5] - 0.2

sim_stats_20_missing_0.1 <-
  read_csv(filename_20_missing_0.1, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.1" = mean(p.value < alpha),
    "bias, ef = 0.1" = 0.1 - median_estimate
  )
sim_stats_20_missing_0.1[1,5] <- sim_stats_20_missing_0.1[1,5] - 0.1

sim_stats_missing <- cbind(sim_stats_20_missing_0.1[,1], 
                           sim_stats_20_missing_0.1[,4], 
                           sim_stats_20_missing_0.2[,4], 
                           sim_stats_20_missing_0.3[,4], 
                           sim_stats_20_missing_0.4[,4], 
                           sim_stats_20_missing_0.5[,4])

sim_stats_missing %>%
  kbl(caption = "Power for Simulations with 20 pct. Missing Data and Varying Intercepts and Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_20_missing_bias <- cbind(sim_stats_20_missing_0.1[,1], 
                           sim_stats_20_missing_0.1[,5], 
                           sim_stats_20_missing_0.2[,5], 
                           sim_stats_20_missing_0.3[,5], 
                           sim_stats_20_missing_0.4[,5], 
                           sim_stats_20_missing_0.5[,5])
```

## Summary Statistics for Power Calculation with 50 pct. Missing Data and Varying Intercepts:

```{r, message = FALSE, warning = FALSE, echo = FALSE}
sim_stats_50_missing_0.5 <-
  read_csv(filename_50_missing_0.5, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.5" = mean(p.value < alpha),
    "bias, ef = 0.5" = 0.5 - median_estimate
  )

sim_stats_50_missing_0.5[1,5] <- sim_stats_50_missing_0.5[1,5] - 0.5

sim_stats_50_missing_0.4 <-
  read_csv(filename_50_missing_0.4, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.4" = mean(p.value < alpha),
    "bias, ef = 0.4" = 0.4 - median_estimate
  )

sim_stats_50_missing_0.4[1,5] <- sim_stats_50_missing_0.4[1,5] - 0.4

sim_stats_50_missing_0.3 <-
  read_csv(filename_50_missing_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.3" = mean(p.value < alpha),
    "bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_50_missing_0.3[1,5] <- sim_stats_50_missing_0.3[1,5] - 0.3

sim_stats_50_missing_0.2 <-
  read_csv(filename_50_missing_0.2, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.2" = mean(p.value < alpha),
    "bias, ef = 0.2" = 0.2 - median_estimate
  )

sim_stats_50_missing_0.2[1,5] <- sim_stats_50_missing_0.2[1,5] - 0.2

sim_stats_50_missing_0.1 <-
  read_csv(filename_50_missing_0.1, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power, ef = 0.1" = mean(p.value < alpha),
    "bias, ef = 0.1" = 0.1 - median_estimate
  )

sim_stats_50_missing_0.1[1,5] <- sim_stats_50_missing_0.1[1,5] - 0.1

sim_stats_missing <- cbind(sim_stats_50_missing_0.1[,1], 
                           sim_stats_50_missing_0.1[,4], 
                           sim_stats_50_missing_0.2[,4], 
                           sim_stats_50_missing_0.3[,4], 
                           sim_stats_50_missing_0.4[,4], 
                           sim_stats_50_missing_0.5[,4])

sim_stats_missing %>%
  kbl(caption = "Power for Simulations with 50 pct. Missing Data and Varying Intercepts and Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_50_missing_bias <- cbind(sim_stats_50_missing_0.1[,1], 
                           sim_stats_50_missing_0.1[,5], 
                           sim_stats_50_missing_0.2[,5], 
                           sim_stats_50_missing_0.3[,5], 
                           sim_stats_50_missing_0.4[,5], 
                           sim_stats_50_missing_0.5[,5])
```

# Overview of Bias Results
```{r, echo = FALSE}
sim_stats_full_bias_int_slope %>%
  kbl(caption = "Bias for Simulations with Full Data and Varying Intercepts and Varying Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_full_bias_int %>%
  kbl(caption = "Bias for Simulations with Full Data and Varying Intercepts", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_20_missing_bias %>%
  kbl(caption = "Bias for Simulations with 20 pct. Missing Data and Varying Intercepts and Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_50_missing_bias %>%
  kbl(caption = "Bias for Simulations with 50 pct. Missing Data and Varying Intercepts and Slopes", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

```

# Grid Search Code
```{r, eval = FALSE}
n_subjects <- c(1280, 1920, 2560)
n_trials <- c(12, 18, 24)
b_parameter <- c(0.3, 0.5, 0.7)
sd_parameter <- c(0.1, 0.2, 0.3)
sigma_parameter <- c(0.1)


run_sims_grid_point  <- function(filename_full, subj_n, trial_n, ef, residual_sd, random_var, random_var_item, rho_val) {
  
  participants_per_lab<-32
  
  n_simple<- trial_n/2
  n_complex<- trial_n/2
  n_small_fam<- trial_n/3
  n_medium_fam<- trial_n/3
  n_high_fam<- trial_n/3
  n_lab<-floor(subj_n/participants_per_lab)
  
  dat_sim <- my_sim_data(n_subj = subj_n,
                         n_simple = n_simple,
                         n_complex = n_complex,
                         n_small_fam = n_small_fam,
                         n_medium_fam = n_medium_fam,
                         n_high_fam = n_high_fam,
                         n_lab = n_lab,
                         beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         beta_cfa = ef,
                         
                         subject_0 = random_var,
                         subject_c = random_var,
                         subject_f = random_var,
                         subject_a = random_var,
                         subject_ca = random_var,
                         subject_af = random_var,
                         subject_cf = random_var,
                         subject_cfa = random_var,
                         subj_rho = rho_val,
                         
                         lab_0 = random_var,
                         lab_c = random_var,
                         lab_f = random_var,
                         lab_a = random_var,
                         lab_ca = random_var,
                         lab_af = random_var,
                         lab_cf = random_var,
                         lab_cfa = random_var,
                         lab_rho = rho_val,
                         
                         item_0 = random_var_item,
                         item_c = random_var_item,
                         item_f = random_var_item,
                         item_a = random_var_item,
                         item_ca = random_var_item,
                         item_af = random_var_item,
                         item_cf = random_var_item,
                         item_cfa = random_var_item,
                         item_rho = rho_val,
                         
                         sigma = residual_sd,
                         )
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=dat_sim)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

reps <- 50

n_subj_values <- c(1280, 1920, 2560)
trial_n_values <- c(12, 18, 24)
random_var <- c(0.1, 0.2)
random_var_item <- c(0.05, 0.1, 0.2)
b_parameter <- c(0.3, 0.5, 0.7)
residual_sd <- c(0.1, 0.3)

param_combinations <- expand.grid(n_subj = n_subj_values,
                                   trial_n = trial_n_values,
                                   random_var = random_var,
                                   random_var_item = random_var_item,
                                   b_parameter = b_parameter,
                                  residual_sd = residual_sd)

for (i in seq_len(nrow(param_combinations))) {
  start_time <- Sys.time()
  
  sim_params <- param_combinations[i, ]
  filename_full <- paste0('sims_grid_search/test_grid_search_', 
                          sim_params$n_subj, '_', 
                          sim_params$trial_n, '_', 
                          sim_params$random_var, '_', 
                          sim_params$random_var_item, '_',
                          sim_params$b_parameter, '_', 
                          sim_params$residual_sd, '.csv')
  
  sims <- purrr::map_df(1:reps, ~run_sims_grid_point(filename_full = filename_full,
                                                     subj_n = sim_params$n_subj, 
                                                     trial_n = sim_params$trial_n, 
                                                     ef = sim_params$b_parameter, 
                                                     random_var = sim_params$random_var, 
                                                     random_var_item = sim_params$random_var_item,
                                                     residual_sd = sim_params$residual_sd,
                                                     rho_val = 0.2))
  
  end_time <- Sys.time()
  cat("Simulation", i, "Time elapsed:", end_time - start_time, "\n")
}
```

```{r, warning = FALSE, message = FALSE}
# set the directory where the CSV files are located
setwd("/work/sims_grid_search")

# get the file names for CSV files
file_names <- list.files(pattern = "*.csv")

# read in all CSV files into a list of dataframes
df_list <- purrr::map(file_names, ~{
  df <- read.csv(.x)
  df$filename <- .x
  df
})

df <- purrr::reduce(df_list, dplyr::bind_rows)

df_per_sim <- df %>%
  filter(effect == "fixed") %>%
  group_by(filename, term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "power" = mean(p.value < 0.05)) %>%
  mutate(n_subj = sapply(strsplit(filename, "_"), `[`,4), 
         Trials = sapply(strsplit(filename, "_"), `[`,5),
         SubjectSD = sapply(strsplit(filename, "_"), `[`,6),
         ItemSD = sapply(strsplit(filename, "_"), `[`,7),
         EffectSize = sapply(strsplit(filename, "_"), `[`,8),
         residual_sd = as.numeric(str_replace(sapply(strsplit(filename, "_"), `[`,9), pattern = ".csv", "")))

error_bars <- df_per_sim %>%
  filter(term != "(Intercept)") %>%
  group_by(EffectSize, SubjectSD, Trials, ItemSD, n_subj, term) %>%
  dplyr::summarise(power_mean = median(power), 
                   power_lci = quantile(power, prob = 0.025), 
                   power_hci = quantile(power, prob = 0.975)) %>%
  filter(term %in% c("X_a", "X_c", "X_f")) %>%
  dplyr::rename(Predictor = term) %>%
  mutate(Predictor = ifelse(Predictor == "X_a", "Age", Predictor)) %>%
  mutate(Predictor = ifelse(Predictor == "X_c", "Complexity", Predictor)) %>%
  mutate(Predictor = ifelse(Predictor == "X_f", "Familiarity", Predictor))

MainEffectGridSearchPlot <- ggplot() +
  geom_point(aes(x = n_subj, y = power_mean, color = Predictor, shape = EffectSize), data = error_bars, size = 2, alpha = 0.8,
             position = position_jitter(width = 0.2, height = 0)) +
  geom_hline(yintercept = 0.95, linetype = 2) +
  scale_color_manual(values = viridis(n = 4)) +
  #scale_fill_manual(values = brewer.pal(n=8, name = 'Dark2')) +
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1), limits = c(0.0, 1.00)) +
  facet_grid(ItemSD ~ SubjectSD + Trials, labeller = label_both) +
  ggtitle('Power for Main Effects') +
  xlab("Number of Subjects") +
  ylab("Power (proportion of runs > 0.05)") +
  theme_bw() +
   theme(strip.background = element_rect(color="white", fill="white", size=5, linetype="solid"), 
        plot.title = element_text(hjust = 0.5, size = 15),
        strip.text.x = element_text(size = 12, color = "black"),
        strip.text.y = element_text(size = 12, color = "black"),
        axis.text.x = element_text(size = 13),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 13),
        axis.title.y = element_text(size = 13))
MainEffectGridSearchPlot

error_bars <- df_per_sim %>%
  filter(term != "(Intercept)") %>%
  group_by(EffectSize, SubjectSD, Trials, ItemSD, n_subj, term) %>%
  dplyr::summarise(power_mean = median(power), 
                   power_lci = quantile(power, prob = 0.025), 
                   power_hci = quantile(power, prob = 0.975)) %>%
  filter(term %in% c("X_a:X_c", "X_a:X_f", "X_c:X_f", "X_a:X_c:X_f")) %>%
  dplyr::rename(Predictor = term) %>%
  mutate(Predictor = ifelse(Predictor == "X_a:X_c", "Age:Complexity", Predictor)) %>%
  mutate(Predictor = ifelse(Predictor == "X_a:X_f", "Age:Familiarity", Predictor)) %>%
  mutate(Predictor = ifelse(Predictor == "X_c:X_f", "Complexity:Familiarity", Predictor)) %>%
  mutate(Predictor = ifelse(Predictor == "X_a:X_c:X_f", "Familiarity:Age:Complexity", Predictor))

InteractionEffectGridSearchPlot <- ggplot() +
  geom_point(aes(x = n_subj, y = power_mean, color = Predictor, shape = EffectSize), data = error_bars, size = 2, alpha = 0.8,
             position = position_jitter(width = 0.25, height = 0)) +
  geom_hline(yintercept = 0.95, linetype = 2) +
  scale_color_manual(values = viridis(n = 5)) +
  #scale_fill_manual(values = brewer.pal(n=8, name = 'Dark2')) +
  scale_y_continuous(breaks = c(0, 0.25, 0.50, 0.75, 1), limits = c(0.0, 1.00)) +
  facet_grid(ItemSD ~ SubjectSD + Trials, labeller = label_both) +
  ggtitle('Power for Interaction Effects') +
  xlab("Number of Subjects") +
  ylab("Power (proportion of runs > 0.05)") +
  theme_bw() +
   theme(strip.background = element_rect(color="white", fill="white", size=5, linetype="solid"), 
        plot.title = element_text(hjust = 0.5, size = 15),
        strip.text.x = element_text(size = 12, color = "black"),
        strip.text.y = element_text(size = 12, color = "black"),
        axis.text.x = element_text(size = 13),
        axis.title.x = element_text(size = 13),
        axis.text.y = element_text(size = 13),
        axis.title.y = element_text(size = 13))

InteractionEffectGridSearchPlot

ggsave(plot = MainEffectGridSearchPlot, file = "MainEffectGridSearchPlot.png", 
       height = 10, 
       width = 15)
ggsave(plot = InteractionEffectGridSearchPlot, file = "InteractionEffectGridSearchPlot.png", 
       height = 10, 
       width = 15)
```

# Power Calculation with Full Data and Varying Intercepts and Varying Slopes

## Effect Size = 0.5

```{r, warning = FALSE, message = FALSE, eval = FALSE}
# Number of simulations:
reps <- 500

# Simulation function:
run_sims <- function(filename_full, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 + X_c * X_f | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=dat_sim)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

filename_full_0.5 = 'run_sims_full_0.5.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.5, ef = 0.5))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.4

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_0.4 = 'run_sims_full_0.4.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.4, ef = 0.4))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.3

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_0.3 = 'run_sims_full_0.3.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.3, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```

### Visualise Estimates for Fixed Effects:

```{r}
sims_full_0.3 <- read_csv(filename_full_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                              term = col_factor(ordered = TRUE)))

fixed_full_plot <- sims_full_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for Full Data and Varying Intercepts and Varying Slopes, ef = 0.3') +
  theme_bw()

fixed_full_plot <- fixed_full_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_full_plot
```

### Visualise Estimates for Random Effects:

```{r}
ran_full_plot <- sims_full_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 13)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects Full Random-Effects Structure, ef = 0.3') +
  theme_bw()
ran_full_plot <- ran_full_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_full_plot
```

## Effect Size = 0.2

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_0.2 = 'run_sims_full_0.2.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.2, ef = 0.2))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.1

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_0.1 = 'run_sims_full_0.1.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.1, ef = 0.1))
end_time <- Sys.time()
end_time - start_time
```

# Power Calculation with Full Data and Varying Intercepts

## Effect Size = 0.5

```{r, warning = FALSE, message = FALSE, eval = FALSE}
# Simulation function:
run_sims <- function(filename_full, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=dat_sim)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

filename_full_int_0.5 = 'run_sims_full_int_0.5.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_int_0.5, ef = 0.5))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.4

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_int_0.4 = 'run_sims_full_int_0.4.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_int_0.4, ef = 0.4))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.3

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_int_0.3 = 'run_sims_full_int_0.3.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_int_0.3, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```

### Visualise Estimates for Fixed Effects:

```{r}
sims_full_int_0.3 <- read_csv(filename_full_int_0.3, col_types = cols(group = col_factor(ordered = TRUE), 
                                                              term = col_factor(ordered = TRUE)))

fixed_full_int_plot <- sims_full_int_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for Full Data and Random Intercepts, ef = 0.3') +
  theme_bw()

fixed_full_int_plot <- fixed_full_int_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_full_int_plot
```

### Visualise Estimates for Random Effects:

```{r}
ran_full_int_plot <- sims_full_int_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, estimate) %>%
  mutate(row = rep(seq(1:reps), 4)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for Full Data, ef = 0.3') +
  theme_bw()
ran_full_int_plot <- ran_full_int_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_full_int_plot
```

## Effect Size = 0.2

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_int_0.2 = 'run_sims_full_int_0.2.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_int_0.2, ef = 0.2))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.1

```{r, warning = FALSE, message = FALSE, eval = FALSE}
filename_full_int_0.1 = 'run_sims_full_int_0.1.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_int_0.1, ef = 0.1))
end_time <- Sys.time()
end_time - start_time
```

# Power Calculation with 20 pct. Missing Data and Varying Intercepts

## Effect Size = 0.5

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
run_sims_missing <- function(filename_missing, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  missing_samples <- dat_sim %>%
    mutate(nas = rbinom(nrow(dat_sim), 1, 1 - .20)) %>%
    mutate(DV = ifelse(nas == 1, DV, NA)) %>%
    drop_na()
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=missing_samples)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_missing)
  write_csv(sim_results, filename_missing, append = append)
  
  # return the tidy table
  sim_results
}

filename_20_missing_0.5 = 'run_sims_20_missing_0.5.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_20_missing_0.5, ef = 0.5))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.4

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_20_missing_0.4 = 'run_sims_20_missing_0.4.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_20_missing_0.4, ef = 0.4))
end_time <- Sys.time()
end_time - start_time
```


## Effect Size = 0.3

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_20_missing_0.3 = 'run_sims_20_missing_0.3.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_20_missing_0.3, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```


### Visualise Estimates for Fixed Effects:

```{r, eval = FALSE}
# read saved simulation data
sims_20_missing_0.3 <- read_csv(filename_20_missing_0.3, col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
))

fixed_missing_plot <- sims_20_missing_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for 20 pct. Missing Data, ef = 0.3') +
  theme_bw()

fixed_missing_plot <- fixed_missing_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_missing_plot
```


### Visualise Estimates for Random Effects:

```{r, eval = FALSE}
ran_missing_plot <- sims_20_missing_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 13)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for 20 pct. Missing Data, ef = 0.3') +
  theme_bw()
ran_missing_plot <- ran_missing_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_missing_plot
```


## Effect Size = 0.2

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_20_missing_0.2 = 'run_sims_20_missing_0.2.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_20_missing_0.2, ef = 0.2))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.1

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_20_missing_0.1 = 'run_sims_20_missing_0.1.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_20_missing_0.1, ef = 0.1))
end_time <- Sys.time()
end_time - start_time
```


# Power Calculation with 50 pct. Missing Data and Varying Intercepts

## Effect Size = 0.5

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
run_sims_missing <- function(filename_missing, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  missing_samples <- dat_sim %>%
    mutate(nas = rbinom(nrow(dat_sim), 1, 1 - .50)) %>%
    mutate(DV = ifelse(nas == 1, DV, NA)) %>%
    drop_na()
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=missing_samples)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_missing)
  write_csv(sim_results, filename_missing, append = append)
  
  # return the tidy table
  sim_results
}

filename_50_missing_0.5 = 'run_sims_50_missing_0.5.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_50_missing_0.5, ef = 0.5))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.4

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_50_missing_0.4 = 'run_sims_50_missing_0.4.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_50_missing_0.4, ef = 0.4))
end_time <- Sys.time()
end_time - start_time
```


## Effect Size = 0.3

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_50_missing_0.3 = 'run_sims_50_missing_0.3.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_50_missing_0.3, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```


### Visualise Estimates for Fixed Effects:

```{r, eval = FALSE}
# read saved simulation data
sims_50_missing_0.3 <- read_csv(filename_50_missing_0.3, col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
))

fixed_missing_plot <- sims_50_missing_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for 50 pct. Missing Data, ef = 0.3') +
  theme_bw()

fixed_missing_plot <- fixed_missing_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_missing_plot
```


### Visualise Estimates for Random Effects:

```{r, eval = FALSE}
ran_missing_plot <- sims_20_missing_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 13)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for 50 pct. Missing Data, ef = 0.3') +
  theme_bw()
ran_missing_plot <- ran_missing_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_missing_plot
```


## Effect Size = 0.2

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_50_missing_0.2 = 'run_sims_50_missing_0.2.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_50_missing_0.2, ef = 0.2))
end_time <- Sys.time()
end_time - start_time
```

## Effect Size = 0.1

```{r,  warning = FALSE, message = FALSE, eval = FALSE}
filename_50_missing_0.1 = 'run_sims_50_missing_0.1.csv'
start_time <- Sys.time()
sims_missing <- purrr::map_df(1:reps, ~run_sims_missing(filename_missing = filename_50_missing_0.1, ef = 0.1))
end_time <- Sys.time()
end_time - start_time
```



```{r, include = FALSE}
# Increasing Variance with Trial Number
## Extracting estimates of increasing variance from the adult pilot data

#download data from adult pilot study:
adult_data <- read.csv('02_processed_lt_data.csv')

stimulus_info_df <- adult_data %>% 
  filter(phase == "pref") %>% 
  mutate(familiar_item = case_when(
    left_stimulus == "familiar" ~ stimulus_processed_left, 
    right_stimulus == "familiar" ~ stimulus_processed_right
  ), 
        novel_item = case_when(
    left_stimulus == "novel" ~ stimulus_processed_left, 
    right_stimulus == "novel" ~ stimulus_processed_right
  )) %>% 
  select(subject, block_number, familiar_item, novel_item) %>% 
  distinct(subject, block_number, .keep_all = TRUE)
  
lt_comparison_df <- adult_data %>% 
  filter(phase == "pref") %>% 
  group_by(subject, exposure_time, block_number, complexity, gaze_location_type) %>% 
  summarise(sum_dwell_time = sum(dwell_time)) %>%
  pivot_wider(names_from = gaze_location_type, 
              values_from = sum_dwell_time) %>% 
  ungroup() %>% 
  left_join(stimulus_info_df, by = c("subject", "block_number")) %>% 
  rename(familiarization_time = exposure_time, 
         stimulus_complexity = complexity, 
         trial_number = block_number, 
        familiar_looking_time = familiar, 
         novel_looking_time = novel, 
         participant = subject) %>% 
  # currently excluding all the empty trials 
  filter(!is.na(familiar_looking_time) & !is.na(novel_looking_time))

lt_comparison_df <- lt_comparison_df %>% 
  mutate(familiarization_time_scaled_centered =
           log10(familiarization_time) - log10(2000), 
         contrast_coded_complexity = ifelse(stimulus_complexity == "complex", 0.5, -0.5))

proportion_df <- adult_data %>% 
  filter(phase == "pref") %>% 
  group_by(block_number, exposure_time,
           complexity, gaze_location_type, subject) %>% 
  summarise(sum_dwell_time = sum(dwell_time, na.rm = TRUE)) %>% 
  pivot_wider(names_from = gaze_location_type, 
              values_from = sum_dwell_time) %>% 
  mutate(familiar = ifelse(is.na(familiar), 0, familiar), 
         novel = ifelse(is.na(novel), 0, novel)) %>% 
  mutate(novelty_looking_proportion = novel / (familiar+novel))

dwell_proportion_mean <- mean(proportion_df$novelty_looking_proportion, na.rm = T)
dwell_proportion_sd <- sd(proportion_df$novelty_looking_proportion, na.rm = T)

adult_data_z <- proportion_df %>%
  mutate(dwell_time_z = (novelty_looking_proportion - dwell_proportion_mean) / dwell_proportion_sd)

data_on_increase_in_sd <- adult_data_z %>%
  group_by(block_number) %>%
  summarise(n = n(), 
            dwell_time_median = median(dwell_time_z, na.rm = T), 
            sd_block = sd(dwell_time_z, na.rm = T))

increase_sd_value <- data_on_increase_in_sd$sd_block[12] - data_on_increase_in_sd$sd_block[1]
increase_sd_value
```



```{r, warning = FALSE, message = FALSE, include = FALSE}
## Visualisation of adult data in proportions
adult_proportion_plot <- proportion_df %>% 
  ggplot(aes(x = as.factor(block_number), y = novelty_looking_proportion, color = complexity)) + 
  geom_jitter(alpha = .3, width = .2) + 
  stat_summary(aes(x = as.factor(block_number), y = novelty_looking_proportion, color = complexity), position = position_dodge(width = .2)) + 
  geom_hline(yintercept = 0.5) +
  scale_color_manual(values=viridis(n = 3)) +
  ggtitle('Adult Pilot Data in Proportions') +
  theme_bw() 
adult_proportion_plot <- adult_proportion_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
adult_proportion_plot
```

```{r, warning = FALSE, message = FALSE, include = FALSE}
## Visualisation of adult data in z-score
adult_data_z_plot <- adult_data_z %>% 
  ggplot(aes(x = as.factor(block_number), y = dwell_time_z, color = complexity)) + 
  geom_jitter(alpha = .3, width = .2) + 
  stat_summary(aes(x = as.factor(block_number), y = dwell_time_z, color = complexity), position = position_dodge(width = .2)) + 
  geom_hline(yintercept = 0.0) + 
  scale_color_manual(values=viridis(n = 3)) +
  ggtitle('Adult Pilot Data in z-scores') +
  theme_bw()

adult_data_z_plot <- adult_data_z_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
adult_data_z_plot
```

```{r, message = FALSE, include = FALSE}
## Modification of simulation function to include variance increase
my_sim_data_variance <- function(
    increase_sd = increase_sd_value, #Add variance to increase with trial number
  
    n_subj      = 1280,   # number of subjects
    n_simple  =  12,   # number of complex stimuli
    n_complex =  12,   # number of complex stimuli
    n_small_fam = 8,   #small familiarization time
    n_medium_fam = 8,  #medium familiarization time
    n_high_fam = 8,    #high familiarization time
    n_lab = 40,
    
    beta_0  =  0, # intercept; i.e., the grand mean
    beta_c  =  0.3, # main effect for complexity
    beta_f = 0.3, # main effect for familiarization time
    beta_a = 0.3, # main effect for age
    
    beta_ca = 0.3,
    beta_af = 0.3,
    beta_cf = 0.3,
    
    beta_cfa = 0.3, #main effect for interaction between complexity and familiarization.
    
    subject_0   = 0.2, # by-subject random intercept sd
    
    subject_c   =  0.2, # by-subject slope complexity sd
    subject_f = 0.2, # by-subject slope familiarization sd
    subject_a = 0.2, # by-subject slope age sd
    
    subject_ca = 0.2,# by-subject slope for interaction between age and complexity sd
    subject_af = 0.2, # by-subject slope for interaction between age and familiarization sd
    subject_cf = 0.2, # by-subject slope complexity*familiarization sd
    
    subject_cfa = 0.2, # by-subject slope for interaction between age, complexity and familiarization sd

    subj_rho     =  .2, # correlations between by-subject random effects
    
    lab_0 = 0.2, # by-lab random intercept sd
    
    lab_c = 0.2, # by-lab slope complexity sd
    lab_f = 0.2, # by-lab slope familiarization sd
    lab_a = 0.2, # by-lab slope age sd
    
    lab_ca = 0.2, # by-lab slope for interaction between age and complexity sd
    lab_af = 0.2, # by-lab slope for interaction between age and familiarization sd
    lab_cf = 0.2, # by-lab random slope complexity*familiarization sd
    
    lab_cfa = 0.2, # by-lab slope for interaction between age, complexity and familiarization sd
    
    lab_rho = 0.2, # correlations between by-lab random effects
    
    item_0 =  0.2, # by-item random intercept sd
    
    item_c = 0.2, # by-item slope complexity sd
    item_f = 0.2, # by-item slope familiarization sd
    item_a = 0.2, # by-item slope age sd
    
    item_ca = 0.2, # by-item slope for interaction between age and complexity sd
    item_af = 0.2, # by-item slope for interaction between age and familiarization sd
    item_cf = 0.2, # by-item random slope complexity*familiarization sd
    
    item_cfa = 0.2, # by-item slope for interaction between age, complexity and familiarization sd
    
    item_rho = 0.2, # correlations between by-item random effects
    
    
    sigma = 0.3 # residual (error) sd
    ) { # residual (standard deviation)
  
  # simulate a sample of items
  items <- data.frame(
    item_id = seq_len(n_simple + n_complex),
    category = rep(c("simple", "complex"), c(n_simple, n_complex)),
    X_c = rep(c(-0.5, 0.5), c(n_simple, n_complex)),
    familiarization = rep(c("short", "medium", "long"), (n_simple + n_complex)/3),
    X_f = rep(c(-0.5, 0, 0.5), (n_simple + n_complex)/3),
    faux::rnorm_multi(
    n = n_simple + n_complex, mu = 0, sd = c(item_0, 
                               item_c, 
                               item_f,
                               item_a,
                               item_ca,
                               item_af,
                               item_cf,
                               item_cfa), r = item_rho,
    varnames = c("I_0", "I_c","I_f","I_a",
                 "I_ca","I_af", "I_cf",
                 "I_cfa"))
    ) %>%
    mutate(item_id = faux::make_id(nrow(.), "I"))
  
  # simulate a sample of subjects
  subjects <- 
    faux::rnorm_multi(
    n = n_subj, mu = 0, sd = c(subject_0, 
                               subject_c, 
                               subject_f,
                               subject_a,
                               subject_ca,
                               subject_af,
                               subject_cf,
                               subject_cfa), r = subj_rho,
    varnames = c("S_0", "S_c","S_f","S_a",
                 "S_ca","S_af", "S_cf",
                 "S_cfa")
  ) %>%
    mutate(subj_id = faux::make_id(nrow(.), "S")) %>%
    mutate(X_a = runif(n_subj, min = -0.5, max = 0.5)) 
  #add subject age measure, sample from distribution from -0.5 to 0.5. #subjects$subj_id <- 1:n_subj
  
  labs <- faux::rnorm_multi(
    n = n_lab, mu = 0, sd = c(lab_0, lab_c, lab_f, lab_a,
                              lab_ca, lab_af, lab_cf,
                              lab_cfa), r = lab_rho, 
    varnames = c("L_0", "L_c","L_f","L_a",
                 "L_ca","L_af", "L_cf",
                 "L_cfa")
  ) %>%
    mutate(lab_id = faux::make_id(nrow(.), "L"))
  
  #create lab and subj nesting structure
  #Number of subjects must be a multiple of number of labs
  lab_multiplier = n_subj/n_lab
  lab_subj_dict <- data.frame(
    subj_id = subjects$subj_id,
    lab_id = rep(labs$lab_id,lab_multiplier)
  )
  
  # cross subject and item IDs 
  temp <- crossing(subjects, items)  %>%
    left_join(lab_subj_dict, by = "subj_id") %>%
    left_join(labs, by = "lab_id") %>%
    group_by(subj_id, item_id) %>% mutate(item_id = sample(item_id)) %>%
    ungroup() %>%
    mutate(trial_num = rep(seq(n_simple + n_complex), n_subj))
      
  temp <- temp %>%
    mutate(trial_i_var = ifelse(trial_num > 0, rnorm(nrow(temp), 0, trial_num*(increase_sd / 24)), 0))
  
  temp %>%
    mutate(
      B_0  = beta_0 + S_0 + L_0 + I_0,
      
      B_c  = beta_c + S_c + L_c + I_c,
      B_f  = beta_f + S_f + L_f + I_f,
      B_a = beta_a + S_a + L_a + I_a,
      
      B_ca = beta_ca + S_ca + L_ca + I_ca,
      B_af = beta_af + S_af + L_af + I_af,
      B_cf = beta_cf + S_cf + L_cf + I_cf,
      
      B_cfa = beta_cfa + S_cfa + L_cfa + I_cfa,
      
      e_si = rnorm(nrow(temp), mean = 0, sd = sigma) + trial_i_var,
      
      DV = B_0 + 
        (B_a * X_a) + (B_c * X_c) + (B_f * X_f) + 
        (B_cf * X_c * X_f) + (B_af * X_a * X_f) + (B_ca * X_c * X_a) + 
        (B_cfa * X_c * X_f * X_a) + e_si
    )
}

dat_sim <- my_sim_data_variance()
```

```{r, include = FALSE}
## Visualise the variance increase
#The increase in variance is over 24 trials in this ManyBabies5 case:
dat_sim <- my_sim_data_variance(increase_sd = increase_sd_value)

plot_trial_num <- dat_sim %>%
  mutate(trial_num = as.factor(trial_num)) %>%
  ggplot() +
  geom_point(aes(y = DV, x = trial_num), position = "jitter", alpha = 0.2, size = 0.2) +
  geom_violin(aes(y = DV, x = trial_num, fill = trial_num), alpha = 0.2, show.legend = FALSE) +
  scale_fill_manual(values=viridis(n = 24)) +
  ggtitle('Increase in Variance across Trial Number') +
  xlab('Trial Number') +
  theme_bw()

plot_trial_num <- plot_trial_num + theme(plot.title = element_text(hjust = 0.5, size=20))
plot_trial_num
```

```{r, include = FALSE}
## Model building and bias assessment
dat_sim <- my_sim_data_variance(increase_sd = increase_sd_value)

mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) +
                    (1 | lab_id) +
                    (1 | item_id),
                  data=dat_sim)

summary(mod_sim)

plot(mod_sim)

qqnorm(resid(mod_sim))
qqline(resid(mod_sim))

check_normality(mod_sim)
check_outliers(mod_sim)
check_collinearity(mod_sim)
check_heteroscedasticity(mod_sim)
```

```{r, warning = FALSE, message = FALSE, eval = FALSE, include = FALSE}
## Test how many of the models violate homoskedasticity
reps <- 200

run_sims_heteroskedasticity <- function(filename_heteroskedasticity) {
  
  dat_sim <- my_sim_data_variance(increase_sd = increase_sd_value)
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) +
                    (1 | lab_id) +
                    (1 | item_id),
                  data=dat_sim)
  
  heteroskedasticity_results <- as_tibble(check_heteroscedasticity(mod_sim)[1])
  
  # append the results to a file
  append <- file.exists(filename_heteroskedasticity)
  write_csv(heteroskedasticity_results, filename_heteroskedasticity, append = append)
  
  # return the tidy table
  heteroskedasticity_results
}

filename_heteroskedasticity = 'sims/filename_heteroskedasticity.csv'
start_time <- Sys.time()
heteroskedasticity_results_data <- purrr::map_df(1:reps, ~run_sims_heteroskedasticity(filename_heteroskedasticity = filename_heteroskedasticity))
end_time <- Sys.time()
end_time - start_time
```

```{r, include = FALSE}
## Overview of how many of the models exhibit homoskedasticity
heteroskedasticity_results <- read.csv(filename_heteroskedasticity)

homoskedastic_models <- heteroskedasticity_results %>%
  filter(value > 0.05)

print(paste0(nrow(homoskedastic_models), "/", nrow(heteroskedasticity_results), " of the models exhibit homoskedasticity"))
```

```{r, eval = FALSE, include = FALSE}
## Bayesian robust location-scale regression model
model_formula <- bf(DV ~ 1 + X_a * X_c * X_f +
                      (1 | subj_id) + (1 | lab_id) + (1 | item_id),
                    sigma ~ 1 + trial_num + (1 | subj_id) + (1 | lab_id) + (1 | item_id))

#get_prior(model_formula, data = dat_sim, family = student)

priors1 <- c(prior(normal(0, 0.5), class = Intercept),
             prior(normal(0, 0.5), class = b),
             prior(normal(0, 0.5), class = b, dpar = sigma),
             prior(normal(0.25, 0.3), class = sd),
             prior(gamma(2, 0.1), class = nu)
             )

heteroskedasticity_fit <- 
  brm(data = dat_sim,
           family = student,
           model_formula,
           prior = priors1,
           sample_prior = "yes",
           iter = 4000,
           warmup = 500,
           #backend = "cmdstanr",
           #threads = threading(2),
           file = "heteroskedasticity_fit",
           cores = 64,
           chains = 2,
           save_pars = save_pars(all = TRUE))

pp_check(heteroskedasticity_fit, ndraws = 100)

heteroskedasticity_fit
```

```{r, eval = FALSE, include = FALSE}
### Prior-Posterior Update Checks
#Sample the parameters of interest:
Posterior_m1 <- as_draws_df(heteroskedasticity_fit)

#Plot the prior-posterior update plot for the intercept:
ggplot(Posterior_m1) +
  geom_density(aes(prior_Intercept), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  theme_classic()

ggplot(Posterior_m1) +
  geom_density(aes(prior_b_sigma), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_sigma_trial_num), fill="#FC4E07", color="black",alpha=0.6) + 
  theme_classic()

ggplot(Posterior_m1) +
  geom_density(aes(prior_sd_item_id), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(sd_subj_id__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(sd_lab_id__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(sd_item_id__Intercept), fill="#FC4E07", color="black",alpha=0.6) + 
  theme_classic()

ggplot(Posterior_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(b_X_a), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(b_X_c), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(b_X_f), fill="#FC4E07", color="black",alpha=0.6) + 
  theme_classic()

ggplot(Posterior_m1) +
  geom_density(aes(prior_b), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(`b_X_a:X_c`), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(`b_X_a:X_f`), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(`b_X_c:X_f`), fill="#FC4E07", color="black",alpha=0.6) + 
  geom_density(aes(`b_X_a:X_c:X_f`), fill="#FC4E07", color="black",alpha=0.6) + 
  theme_classic()

ggplot(Posterior_m1) +
  geom_density(aes(prior_nu), fill="steelblue", color="black",alpha=0.6) +
  geom_density(aes(nu), fill="#FC4E07", color="black",alpha=0.6) +
  theme_classic()
```

```{r, include = FALSE}
# Data missing not completely at random
## Simulation of missing data according to increasing infant age
#back to assumptions of equal variance across trials:
dat_sim <- my_sim_data()

# Proportion of missing data increases with age:
missing_samples_age <- dat_sim %>%
  mutate(nas = rbinom(n(), 1, 0.95 - ifelse(X_a > -0.5, (X_a+0.5)*0.50, 0))) %>%
  mutate(DV = ifelse(nas == 1, DV, NA))

missing_age_plot <- missing_samples_age %>%
  drop_na() %>%
  ggplot() +
  ggtitle("DV as a function of age, missing data") +
  geom_point(aes(x = X_a, y = DV), alpha = 0.3, size = 0.2, position = "jitter") +
  geom_smooth(aes(x = X_a, y = DV), method = "lm", se = TRUE, formula = y ~ x) +
  theme_bw()

missing_age_plot <- missing_age_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
missing_age_plot
```

```{r, warning = FALSE, message = FALSE, eval = FALSE, include = FALSE}
### Simulation of models
# Number of simulations:
reps <- 100

# Simulation function:
run_sims <- function(filename_full, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  missing_samples_age <- dat_sim %>%
    mutate(nas = rbinom(n(), 1, 0.95 - ifelse(X_a > -0.5, (X_a+0.5)*0.50, 0))) %>%
    mutate(DV = ifelse(nas == 1, DV, NA))
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=missing_samples_age)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

filename_full_0.3_missing_age = 'sims/run_sims_0.3_age_missing.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.3_missing_age, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```

```{r, eval = FALSE, include = FALSE}
### Visualise Estimates for Fixed Effects:
# read saved simulation data
sims_50_missing_age_0.3 <- read_csv(filename_full_0.3_missing_age, col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
))

reps <- 100

fixed_missing_age_plot <- sims_50_missing_age_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for Missing Data with Age, ef = 0.3') +
  theme_bw()

fixed_missing_age_plot <- fixed_missing_age_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_missing_age_plot
```

```{r, eval = FALSE, include = FALSE}
### Visualise Estimates for Random Effects:
ran_missing_age_plot <- sims_50_missing_age_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 4)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for Missing Data with Age, ef = 0.3') +
  theme_bw()
ran_missing_age_plot <- ran_missing_age_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_missing_age_plot
```

```{r, eval = FALSE, include = FALSE}
## Simulation of missing data according to increasing trial number
# Proportion of missing data increases with trial number:
missing_samples_trial <- dat_sim %>%
  mutate(nas = rbinom(n(), 1, 0.95 - ifelse(trial_num > 0, trial_num*0.025, 0))) %>%
  mutate(DV = ifelse(nas == 1, DV, NA))

missing_trialnum_plot <- missing_samples_trial %>%
  drop_na() %>%
  ggplot() +
  geom_point(aes(x = trial_num, y = DV), alpha = 0.3, size = 0.2, position = "jitter") +
  geom_smooth(aes(x = trial_num, y = DV), method = "lm", se = TRUE, formula = y ~ x) +
  ggtitle("DV as a function of trial number, missing data") +
  theme_bw()

missing_trialnum_plot <- missing_trialnum_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
missing_trialnum_plot
```

```{r, warning = FALSE, message = FALSE, eval = FALSE, include = FALSE}
### Simulation of models
# Number of simulations:
reps <- 100

# Simulation function:
run_sims <- function(filename_full, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  missing_samples_trial <- dat_sim %>%
    mutate(nas = rbinom(n(), 1, 0.95 - ifelse(trial_num > 0, trial_num*0.025, 0))) %>%
    mutate(DV = ifelse(nas == 1, DV, NA))
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=missing_samples_trial)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

filename_full_0.3_missing_trial = 'sims/run_sims_0.3_trial_missing.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.3_missing_trial, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```

```{r, eval = FALSE, include = FALSE}
### Visualise Estimates for Fixed Effects:
# read saved simulation data
sims_50_missing_trial_0.3 <- read_csv(filename_full_0.3_missing_trial, col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
))

fixed_missing_trial_plot <- sims_50_missing_trial_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for Missing Data with Trial Number, ef = 0.3') +
  theme_bw()

fixed_missing_trial_plot <- fixed_missing_trial_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_missing_trial_plot
```

```{r, eval = FALSE, include = FALSE}
### Visualise Estimates for Random Effects:
ran_missing_trial_plot <- sims_50_missing_trial_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 4)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for Missing Data with Trial, ef = 0.3') +
  theme_bw()
ran_missing_trial_plot <- ran_missing_trial_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_missing_trial_plot
```

```{r, eval = FALSE, include = FALSE}
## Simulation of missing data according to increasing familiarisation
# Proportion of missing data increases with familiarisation:
missing_samples_fam <- dat_sim %>%
  mutate(nas = rbinom(n(), 1, 0.95 - ifelse(X_f > -0.5, (X_f+0.5)*0.6, 0))) %>%
  mutate(DV = ifelse(nas == 1, DV, NA))

missing_samples_fam %>%
  mutate(X_f = as.factor(X_f)) %>%
  drop_na() %>%
  ggplot() +
  geom_point(aes(x = X_f, y = DV), alpha = 0.3, size = 0.2, position = "jitter") +
  geom_violin(aes(y = DV, x = X_f, fill = familiarization), alpha = 0.2) +
  theme_bw()
```

```{r, warning = FALSE, message = FALSE, eval = FALSE, include=FALSE}
### Simulation of models
# Number of simulations:
reps <- 100

# Simulation function:
run_sims <- function(filename_full, ef) {
  
  dat_sim <- my_sim_data(beta_c  =  ef, 
                         beta_f = ef,
                         beta_a = ef,
                         
                         beta_ca = ef,
                         beta_af = ef,
                         beta_cf = ef,
                         
                         beta_cfa = ef)
  
  missing_samples_fam <- dat_sim %>%
    mutate(nas = rbinom(n(), 1, 0.95 - ifelse(X_f > -0.5, (X_f+0.5)*0.6, 0))) %>%
    mutate(DV = ifelse(nas == 1, DV, NA))
  
  mod_sim <- lmer(DV ~ 1 + X_a * X_c * X_f + 
                    (1 | subj_id) + 
                    (1 | lab_id) + 
                    (1 | item_id), 
                  data=missing_samples_fam)
  
  sim_results <- broom.mixed::tidy(mod_sim)
  
  # append the results to a file
  append <- file.exists(filename_full)
  write_csv(sim_results, filename_full, append = append)
  
  # return the tidy table
  sim_results
}

filename_full_0.3_missing_fam = 'sims/run_sims_0.3_fam_missing.csv'
start_time <- Sys.time()
sims <- purrr::map_df(1:reps, ~run_sims(filename_full = filename_full_0.3_missing_fam, ef = 0.3))
end_time <- Sys.time()
end_time - start_time
```

```{r, eval = FALSE, include = FALSE}
### Visualise Estimates for Fixed Effects:
# read saved simulation data
sims_50_missing_fam_0.3 <- read_csv(filename_full_0.3_missing_fam, col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
))

fixed_missing_fam_plot <- sims_50_missing_fam_0.3 %>%
  filter(effect == "fixed") %>%
  ungroup() %>%
  arrange(term, estimate) %>%
  mutate(row = rep(seq(1:reps), 8)) %>%
  ggplot(aes(x = row, y = estimate, ymin = estimate-std.error, ymax = estimate+std.error)) +
  facet_wrap(~term, scales = "free") +
  geom_pointrange(fatten = 1/2) +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Fixed Effects for Missing Data with Familiarisation, ef = 0.3') +
  theme_bw()

fixed_missing_fam_plot <- fixed_missing_fam_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
fixed_missing_fam_plot
```

```{r, eval = FALSE, include=FALSE}
### Visualise Estimates for Random Effects:
ran_missing_fam_plot <- sims_50_missing_fam_0.3 %>%
  filter(effect == "ran_pars") %>%
  ungroup() %>%
  arrange(group, term, estimate) %>%
  mutate(row = rep(seq(1:reps), 4)) %>%
  ggplot(aes(x = row, y = estimate)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~group + term, scales = "free_y") +
  theme_bw() +
  ylab("Estimates") +
  xlab("Simulations") +
  ggtitle('Estimates of Random Effects for Missing Data with Familiarisation, ef = 0.3') +
  theme_bw()
ran_missing_fam_plot <- ran_missing_fam_plot + theme(plot.title = element_text(hjust = 0.5, size=20))
ran_missing_fam_plot
```

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval = FALSE, include = FALSE}
# Summary Statistics for Power Calculation with Data missing not completely at random
alpha <- 0.05

sim_stats_full_0.3_age <- 
  read_csv(filename_full_0.3_missing_age, 
           col_types = cols(group = col_factor(ordered = TRUE), 
                            term = col_factor(ordered = TRUE))) %>%
  dplyr::filter(effect == "fixed") %>%
  group_by(term) %>%
  dplyr::summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "missing with age" = mean(`p.value`< alpha),
    "age bias, ef = 0.3" = 0.3 - median_estimate)

sim_stats_full_0.3_age[1,5] <- sim_stats_full_0.3_age[1,5] - 0.3

sim_stats_full_0.3_trial <-
  read_csv(filename_full_0.3_missing_trial, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "missing with trial" = mean(p.value < alpha),
    "trial bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_full_0.3_trial[1,5] <- sim_stats_full_0.3_trial[1,5] - 0.3

sim_stats_full_0.3_fam <-
  read_csv(filename_full_0.3_missing_fam, col_types = cols(group = col_factor(ordered = TRUE), 
                                                  term = col_factor(ordered = TRUE))) %>%
  filter(effect == "fixed") %>%
  group_by(term) %>%
  summarise(
    median_estimate = median(estimate),
    median_se = median(std.error),
    "missing with fam" = mean(p.value < alpha),
    "fam bias, ef = 0.3" = 0.3 - median_estimate
  )

sim_stats_full_0.3_fam[1,5] <- sim_stats_full_0.3_fam[1,5] - 0.3

sim_stats_full <- cbind(sim_stats_full_0.3_age[,1],
                        sim_stats_full_0.3_age[,4],
                        sim_stats_full_0.3_trial[,4], 
                        sim_stats_full_0.3_fam[,4])

sim_stats_full %>%
  kbl(caption = "Power for Simulations with Non-Random Missing Data and Varying Intercepts", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))

sim_stats_full_bias <- cbind(sim_stats_full_0.3_age[,1],
                        sim_stats_full_0.3_age[,5],
                        sim_stats_full_0.3_trial[,5], 
                        sim_stats_full_0.3_fam[,5])

sim_stats_full_bias %>%
  kbl(caption = "Bias for Simulations with Non-Random Missing Data and Varying Intercepts", digits=3, align = "c") %>%
  kable_styling(full_width = T, latex_options = c("striped", "HOLD_position"))
```

```{r, eval = FALSE, include = FALSE}
# Logistic Regression Models
m_missing_age <- glmer(nas ~ X_f + X_a + X_c + trial_num + 
                         (1 | subj_id) + (1 | lab_id) + (1 | item_id), 
                       data = missing_samples_age, 
                       family = binomial)

summary(m_missing_age)

m_missing_fam <- glmer(nas ~ X_f + X_a + X_c + trial_num + 
                         (1 | subj_id) + (1 | lab_id) + (1 | item_id), 
                       data = missing_samples_fam, 
                       family = binomial)

summary(m_missing_fam)

m_missing_trial <- glmer(nas ~ X_f + X_a + X_c + trial_num + 
                         (1 | subj_id) + (1 | lab_id) + (1 | item_id), 
                       data = missing_samples_trial, 
                       family = binomial)

summary(m_missing_trial)
```
